{
    "code": "import pandas as pd\nimport os\nimport io\n\n# Define the upload directory\nupload_dir = \"uploads/9aa18181-2c17-4945-b07c-a4c2bf647728\"\nos.makedirs(upload_dir, exist_ok=True)\n\n# S3 path for the parquet files\ns3_path = 's3://indian-high-court-judgments/metadata/parquet/year=*/court=*/bench=*/metadata.parquet'\n\n# Required columns for the analysis\nrequired_columns = ['court', 'year', 'date_of_registration', 'decision_date']\n\n# Read the parquet files from S3\n# Using 'anon': True for anonymous S3 access as it's a public bucket.\n# Specifying region_name for faster access.\ndf = pd.read_parquet(\n    s3_path,\n    columns=required_columns,\n    storage_options={'anon': True, 'client_kwargs': {'region_name': 'ap-south-1'}}\n)\n\n# Store the collected data to a CSV file\noutput_csv_path = os.path.join(upload_dir, \"data.csv\")\ndf.to_csv(output_csv_path, index=False)\n\n# Collect metadata about the DataFrame\nmetadata_path = os.path.join(upload_dir, \"metadata.txt\")\n\nwith open(metadata_path, 'w') as f:\n    f.write(\"--- Data Description ---\\n\")\n    f.write(f\"File path: {output_csv_path}\\n\")\n    f.write(\"Description: This CSV file contains a subset of columns (court, year, date_of_registration, decision_date) from the Indian High Court Judgments dataset, scraped from public S3 parquet files.\\n\\n\")\n\n    f.write(\"--- DataFrame Info ---\\n\")\n    # Redirect df.info() to a string\n    buf = io.StringIO()\n    df.info(buf=buf)\n    f.write(buf.getvalue())\n    f.write(\"\\n\")\n\n    f.write(\"--- DataFrame Columns ---\\n\")\n    f.write(str(df.columns.tolist()))\n    f.write(\"\\n\\n\")\n\n    f.write(\"--- DataFrame Head ---\\n\")\n    f.write(df.head().to_string())\n    f.write(\"\\n\\n\")\n\n    f.write(\"--- Original JSON Answer Format ---\\n\")\n    f.write(\"{\\n\")\n    f.write(\"  \\\"Which high court disposed the most cases from 2019 - 2022?\\\": \\\"...\\\",\\n\")\n    f.write(\"  \\\"What's the regression slope of the date_of_registration - decision_date by year in the court=33_10?\\\": \\\"...\\\",\\n\")\n    f.write(\"  \\\"Plot the year and # of days of delay from the above question as a scatterplot with a regression line. Encode as a base64 data URI under 100,000 characters\\\": \\\"data:image/webp:base64,...\\\"\\n\")\n    f.write(\"}\\n\")",
    "libraries": [
        "pandas",
        "s3fs"
    ],
    "questions": [
        "Which high court disposed the most cases from 2019 - 2022?",
        "What's the regression slope of the date_of_registration - decision_date by year in the court=33_10?",
        "Plot the year and # of days of delay from the above question as a scatterplot with a regression line. Encode as a base64 data URI under 100,000 characters"
    ],
    "comment": "Step-3: Getting scrap code and metadata from llm. Tries count = %d 1"
}{
    "code": "import pandas as pd\nimport s3fs\nimport os\nimport io\n\n# Define the output directory\noutput_dir = \"uploads/9aa18181-2c17-4945-b07c-a4c2bf647728\"\nos.makedirs(output_dir, exist_ok=True)\n\n# Initialize S3 filesystem\n# Use anon=True for public buckets and specify region_name as per DuckDB query\nfs = s3fs.S3FileSystem(anon=True, client_kwargs={'region_name': 'ap-south-1'})\n\ns3_bucket = \"indian-high-court-judgments\"\nbase_s3_parquet_path = f\"{s3_bucket}/metadata/parquet/\"\n\nall_parquet_s3_paths = []\nyears_to_collect = range(2019, 2023) # Includes 2019, 2020, 2021, 2022\n\nfor year in years_to_collect:\n    # Glob for all 'metadata.parquet' files within the year's directory structure\n    # s3fs.glob returns paths relative to the bucket or full paths if specified with bucket name\n    year_glob_pattern = f\"{base_s3_parquet_path}year={year}/*/*/metadata.parquet\"\n    files_in_year = fs.glob(year_glob_pattern)\n    \n    # Prepend 's3://' to the paths to make them readable by pandas.read_parquet\n    all_parquet_s3_paths.extend([f\"s3://{f}\" for f in files_in_year])\n\n# Define columns to load based on the questions to optimize memory usage\ncolumns_to_load = [\n    'court',\n    'disposal_nature',\n    'date_of_registration',\n    'decision_date',\n    'year'\n]\n\ndf = pd.DataFrame()\nif all_parquet_s3_paths:\n    # Load the data from all identified parquet files in S3\n    # Pass storage_options to handle S3 authentication/configuration\n    df = pd.read_parquet(\n        all_parquet_s3_paths,\n        columns=columns_to_load,\n        storage_options={'anon': True, 'client_kwargs': {'region_name': 'ap-south-1'}}\n    )\nelse:\n    print(\"No parquet files found for the specified years. DataFrame will be empty.\")\n\n# Save the combined DataFrame to a CSV file\noutput_csv_path = os.path.join(output_dir, \"data.csv\")\ndf.to_csv(output_csv_path, index=False)\n\n# Collect metadata about the scraped data\nmetadata_file_path = os.path.join(output_dir, \"metadata.txt\")\nwith open(metadata_file_path, 'w') as f:\n    f.write(\"--- DataFrame Info ---\\n\")\n    buffer = io.StringIO()\n    df.info(buf=buffer)\n    f.write(buffer.getvalue())\n    f.write(\"\\n\\n--- DataFrame Columns ---\\n\")\n    f.write(str(df.columns.tolist()))\n    f.write(\"\\n\\n--- DataFrame Head ---\\n\")\n    f.write(df.head().to_string())\n    f.write(\"\\n\\n--- Expected JSON Answer Format ---\\n\")\n    f.write(\"\"\"{\n  \"Which high court disposed the most cases from 2019 - 2022?\": \"...\",\n  \"What's the regression slope of the date_of_registration - decision_date by year in the court=33_10?\": \"...\",\n  \"Plot the year and # of days of delay from the above question as a scatterplot with a regression line. Encode as a base64 data URI under 100,000 characters\": \"data:image/webp:base64,...\"\n}\"\"\")\n",
    "libraries": [
        "pandas",
        "s3fs",
        "pyarrow"
    ],
    "questions": [
        "Which high court disposed the most cases from 2019 - 2022?",
        "What's the regression slope of the date_of_registration - decision_date by year in the court=33_10?",
        "Plot the year and # of days of delay from the above question as a scatterplot with a regression line. Encode as a base64 data URI under 100,000 characters"
    ],
    "comment": "Step-4: Error occured while scrapping. Tries count = %d, 0"
}{
    "code": "import pandas as pd\nimport os\nimport io\n\noutput_folder = \"uploads/9aa18181-2c17-4945-b07c-4c2bf647728\"\noutput_data_path = os.path.join(output_folder, \"data.csv\")\nmetadata_path = os.path.join(output_folder, \"metadata.txt\")\n\nos.makedirs(output_folder, exist_ok=True)\n\ns3_base_path = \"s3://indian-high-court-judgments/metadata/parquet/\"\nyears_to_consider = [2019, 2020, 2021, 2022]\ns3_paths = [\n    f\"{s3_base_path}year={year}/court=*/bench=*/metadata.parquet\"\n    for year in years_to_consider\n]\nstorage_options = {\n    'anon': True,\n    'client_kwargs': {'region_name': 'ap-south-1'}\n}\n\ncolumns_needed = [\n    'court',\n    'decision_date',\n    'date_of_registration',\n    'year'\n]\n\ntry:\n    df = pd.read_parquet(s3_paths, columns=columns_needed, storage_options=storage_options)\n\n    df.to_csv(output_data_path, index=False)\n\n    with open(metadata_path, 'w') as f:\n        f.write(\"--- File Description ---\\n\")\n        f.write(f\"This file contains high court judgment metadata for years {min(years_to_consider)}-{max(years_to_consider)}, collected from S3. \\n\")\n        f.write(f\"The data is stored in '{output_data_path}'.\\n\\n\")\n\n        f.write(\"--- DataFrame Info ---\\n\")\n        buffer = io.StringIO()\n        df.info(buf=buffer)\n        f.write(buffer.getvalue())\n        f.write(\"\\n\\n\")\n\n        f.write(\"--- Columns ---\\n\")\n        f.write(str(df.columns.tolist()))\n        f.write(\"\\n\\n\")\n\n        f.write(\"--- Head ---\\n\")\n        f.write(str(df.head()))\n        f.write(\"\\n\\n\")\n\n        f.write(\"--- JSON Answer Format (Not filled by this script) ---\\n\")\n        f.write(\"\"\"{  \"Which high court disposed the most cases from 2019 - 2022?\": \"...\",  \"What's the regression slope of the date_of_registration - decision_date by year in the court=33_10?\": \"...\",  \"Plot the year and # of days of delay from the above question as a scatterplot with a regression line. Encode as a base64 data URI under 100,000 characters\": \"data:image/webp:base64,...\"}\"\"\")\n\nexcept Exception as e:\n    with open(metadata_path, 'w') as f:\n        f.write(f\"Error during data collection: {e}\\n\")\n    raise",
    "libraries": [
        "pandas",
        "s3fs"
    ],
    "questions": [
        "Which high court disposed the most cases from 2019 - 2022?",
        "What's the regression slope of the date_of_registration - decision_date by year in the court=33_10?",
        "Plot the year and # of days of delay from the above question as a scatterplot with a regression line. Encode as a base64 data URI under 100,000 characters"
    ],
    "comment": "Step-4: Error occured while scrapping. Tries count = %d, 1"
}{
    "code": "import pandas as pd\nimport os\nimport s3fs\nimport io\n\n# Define the output directory\noutput_dir = 'uploads/9aa18181-2c17-4945-b07c-4a2cbf647728'\n\n# Create the output directory if it doesn't exist\nos.makedirs(output_dir, exist_ok=True)\n\n# S3 path to the parquet files\ns3_path = 's3://indian-high-court-judgments/metadata/parquet/year=*/court=*/bench=*/metadata.parquet'\n\n# Read the parquet files from S3 into a pandas DataFrame\n# s3fs will be used automatically by pandas if installed\ndf = pd.read_parquet(s3_path, storage_options={'anon': True, 'client_kwargs': {'region_name': 'ap-south-1'}})\n\n# Define the path for the output CSV file\ncsv_output_path = os.path.join(output_dir, 'data.csv')\n\n# Save the DataFrame to a CSV file\ndf.to_csv(csv_output_path, index=False)\n\n# Collect metadata\nmetadata_output_path = os.path.join(output_dir, 'metadata.txt')\n\nwith open(metadata_output_path, 'w') as f:\n    f.write('--- DataFrame Info ---\\n')\n    buffer = io.StringIO()\n    df.info(buf=buffer)\n    f.write(buffer.getvalue())\n    f.write('\\n--- DataFrame Columns ---\\n')\n    f.write(str(df.columns.tolist()))\n    f.write('\\n\\n--- DataFrame Head ---\\n')\n    f.write(str(df.head().to_dict('records')))\n    f.write('\\n\\n--- JSON Answer Format ---\\n')\n    f.write('{\\n')\n    f.write('  \"Which high court disposed the most cases from 2019 - 2022?\": \"...\",\\n')\n    f.write('  \"What\\'s the regression slope of the date_of_registration - decision_date by year in the court=33_10?\": \"...\",\\n')\n    f.write('  \"Plot the year and # of days of delay from the above question as a scatterplot with a regression line. Encode as a base64 data URI under 100,000 characters\": \"data:image/webp:base64,...\"\\n')\n    f.write('}\\n')\n\nprint(f\"Data saved to {csv_output_path}\")\nprint(f\"Metadata saved to {metadata_output_path}\")",
    "libraries": [
        "pandas",
        "s3fs",
        "pyarrow"
    ],
    "questions": [
        "Which high court disposed the most cases from 2019 - 2022?",
        "What's the regression slope of the date_of_registration - decision_date by year in the court=33_10?",
        "Plot the year and # of days of delay from the above question as a scatterplot with a regression line. Encode as a base64 data URI under 100,000 characters"
    ],
    "comment": "Step-4: Error occured while scrapping. Tries count = %d, 2"
}